{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "load_data.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "SaW1L6VyuMvy"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import requests\n",
        "import string\n",
        "import tarfile\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load Numpy Arrays**\n",
        "\n",
        "Build a data pipeline over numpy arrays."
      ],
      "metadata": {
        "id": "gPHxJR6kuZdR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a toy dataset\n",
        "evens = np.arange(0, 100, step=2, dtype=np.int32)\n",
        "evens_label = np.zeros(50, dtype=np.int32)\n",
        "odds = np.arange(1, 100, step=2, dtype=np.int32)\n",
        "odds_label = np.ones(50, dtype=np.int32)\n",
        "# Concatenate arrays\n",
        "features = np.concatenate([evens, odds])\n",
        "labels = np.concatenate([evens_label, odds_label])\n",
        "\n",
        "# Load a numpy array using tf data api with `from_tensor_slices`.\n",
        "data = tf.data.Dataset.from_tensor_slices((features, labels))\n",
        "# Refill data indefinitely.\n",
        "data = data.repeat()\n",
        "# Shuffle data\n",
        "data = data.shuffle(buffer_size=100)\n",
        "# Batch data\n",
        "data = data.batch(batch_size=4)\n",
        "# Prefetch batch (pre-load batch for faster consumption).\n",
        "data = data.prefetch(buffer_size=1)"
      ],
      "metadata": {
        "id": "W2kE8q3ouYdQ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for batch_x, batch_y in data.take(5):\n",
        "    print(batch_x, batch_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mLPr3QDNPTG7",
        "outputId": "da43277d-0687-48ef-f03f-2b3f3efd62fb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([75 68 35 67], shape=(4,), dtype=int32) tf.Tensor([1 0 1 1], shape=(4,), dtype=int32)\n",
            "tf.Tensor([11 51 78 77], shape=(4,), dtype=int32) tf.Tensor([1 1 0 1], shape=(4,), dtype=int32)\n",
            "tf.Tensor([18 80 81 97], shape=(4,), dtype=int32) tf.Tensor([0 0 1 1], shape=(4,), dtype=int32)\n",
            "tf.Tensor([15 43 38 22], shape=(4,), dtype=int32) tf.Tensor([1 1 0 0], shape=(4,), dtype=int32)\n",
            "tf.Tensor([ 1  4 34 61], shape=(4,), dtype=int32) tf.Tensor([1 0 0 1], shape=(4,), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Note: If you are planning on calling multiple time,\n",
        "# you can user the iterator way:\n",
        "ite_data = iter(data)\n",
        "for i in range(5):\n",
        "    batch_x, batch_y = next(ite_data)\n",
        "    print(batch_x, batch_y)\n",
        "\n",
        "for i in range(5):\n",
        "    batch_x, batch_y = next(ite_data)\n",
        "    print(batch_x, batch_y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZnWID68XUda1",
        "outputId": "cce55eb2-e060-4e85-8e6f-d82b71e69535"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([33 46  5 93], shape=(4,), dtype=int32) tf.Tensor([1 0 1 1], shape=(4,), dtype=int32)\n",
            "tf.Tensor([24  6 57 74], shape=(4,), dtype=int32) tf.Tensor([0 0 1 0], shape=(4,), dtype=int32)\n",
            "tf.Tensor([54 14 53 25], shape=(4,), dtype=int32) tf.Tensor([0 0 1 1], shape=(4,), dtype=int32)\n",
            "tf.Tensor([12 84 37 71], shape=(4,), dtype=int32) tf.Tensor([0 0 1 1], shape=(4,), dtype=int32)\n",
            "tf.Tensor([64 94 65 29], shape=(4,), dtype=int32) tf.Tensor([0 0 1 1], shape=(4,), dtype=int32)\n",
            "tf.Tensor([14 66 15  8], shape=(4,), dtype=int32) tf.Tensor([0 0 1 0], shape=(4,), dtype=int32)\n",
            "tf.Tensor([79 43 76  9], shape=(4,), dtype=int32) tf.Tensor([1 1 0 1], shape=(4,), dtype=int32)\n",
            "tf.Tensor([52 92 20 22], shape=(4,), dtype=int32) tf.Tensor([0 0 0 0], shape=(4,), dtype=int32)\n",
            "tf.Tensor([19 26 72 48], shape=(4,), dtype=int32) tf.Tensor([1 0 0 0], shape=(4,), dtype=int32)\n",
            "tf.Tensor([96 31 91 73], shape=(4,), dtype=int32) tf.Tensor([0 1 1 1], shape=(4,), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load CSV files**"
      ],
      "metadata": {
        "id": "iocpKVLrVR0Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# download Titanic dataset (in csv format).\n",
        "d = requests.get(\"https://raw.githubusercontent.com/tflearn/tflearn.github.io/master/resources/titanic_dataset.csv\")\n",
        "with open(\"titanic_dataset.csv\", \"wb\") as f:\n",
        "    f.write(d.content)"
      ],
      "metadata": {
        "id": "vRp79cfNVObs"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Titanic dataset.\n",
        "# Original features: survived,pclass,name,sex,age,sibsp,parch,ticket,fare\n",
        "# Select specific columns: survived,pclass,name,sex,age,fare\n",
        "column_to_use = [0, 1, 2, 3, 4, 8]\n",
        "record_defaults = [tf.int32, tf.int32, tf.string, tf.string, tf.float32, tf.float32]\n",
        "\n",
        "# Load the whole dataset file, and slice each line.\n",
        "data = tf.data.experimental.CsvDataset(\"titanic_dataset.csv\", record_defaults, header=True, select_cols=column_to_use)\n",
        "# Refill data indefinitely.\n",
        "data = data.repeat()\n",
        "# Shuffle data\n",
        "data = data.shuffle(buffer_size=1000)\n",
        "# Batch data (aggregate records together).\n",
        "data = data.batch(batch_size=2)\n",
        "# Prefetcb batch (pre-load batch for faster consumption).\n",
        "data = data.prefetch(buffer_size=1)"
      ],
      "metadata": {
        "id": "oXtCaFxyVlaz"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for survived, pclass, name, sex, age, fare in data.take(1):\n",
        "    print(survived.numpy())\n",
        "    print(pclass.numpy())\n",
        "    print(name.numpy())\n",
        "    print(sex.numpy())\n",
        "    print(age.numpy())\n",
        "    print(fare.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUZQzm3oWVmu",
        "outputId": "4ac72ddc-f1d9-45a6-fb5a-fc9e9d578ac7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0]\n",
            "[3 3]\n",
            "[b'Lennon, Mr. Denis' b'Elias, Mr. Dibo']\n",
            "[b'male' b'male']\n",
            "[0. 0.]\n",
            "[15.5    7.225]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load Images**"
      ],
      "metadata": {
        "id": "DkkHAzzGWrIA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download Oxford 17 flowers dataset\n",
        "d = requests.get(\"http://www.robots.ox.ac.uk/~vgg/data/flowers/17/17flowers.tgz\")\n",
        "with open(\"17flowers.tgz\", \"wb\") as f:\n",
        "    f.write(d.content)\n",
        "# Extract archive.\n",
        "with tarfile.open(\"17flowers.tgz\") as t:\n",
        "    t.extractall()"
      ],
      "metadata": {
        "id": "czbFqKyLWbQ0"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('jpg/dataset.csv', 'w') as f:\n",
        "    c = 0\n",
        "    for i in range(1360):\n",
        "        f.write(\"jpg/image_%04i.jpg,%i\\n\" % (i+1, c))\n",
        "        if (i+1) % 80 == 0:\n",
        "            c += 1"
      ],
      "metadata": {
        "id": "tKA0qDhlXIvG"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Images\n",
        "with open(\"jpg/dataset.csv\") as f:\n",
        "    dataset_file = f.read().splitlines()\n",
        "\n",
        "# Load the whole dataset file, and slice each line.\n",
        "data = tf.data.Dataset.from_tensor_slices(dataset_file)\n",
        "# Refill data Indefinitely.\n",
        "data = data.repeat()\n",
        "# Shuffle data.\n",
        "data = data.shuffle(buffer_size=1000)\n",
        "\n",
        "# Load and pre-process images.\n",
        "def load_image(path):\n",
        "    # Read image from path.\n",
        "    image = tf.io.read_file(path)\n",
        "    # Decode the jpeg image to array [0, 255].\n",
        "    image = tf.image.decode_jpeg(image)\n",
        "    # Resize images to a common size of 256x256\n",
        "    image = tf.image.resize(image, [256, 256])\n",
        "    # Rescale values to [-1, 1].\n",
        "    image = 1. - image / 127.5\n",
        "    return image\n",
        "\n",
        "# Decode each line from the dataset file.\n",
        "def parse_records(line):\n",
        "    # File is in csv format: \"image_path, label_id\".\n",
        "    # TensorFlow requires a default value, but it will never be used.\n",
        "    image_path, image_label = tf.io.decode_csv(line, [\"\", 0])\n",
        "    # Apply the function to load images.\n",
        "    image = load_image(image_path)\n",
        "    return image, image_label\n",
        "\n",
        "# Use 'map' to apply the above functions in parallel.\n",
        "data = data.map(parse_records, num_parallel_calls=4)\n",
        "\n",
        "# Batch data (aggregate images-array together).\n",
        "data = data.batch(batch_size=2)\n",
        "# Prefetch batch (pre-load batch for faster consumption).\n",
        "data = data.prefetch(buffer_size=1)"
      ],
      "metadata": {
        "id": "mx-xVpTrXnWB"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for batch_x, batch_y in data.take(1):\n",
        "    print(batch_x, batch_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RdN1fyVSbayC",
        "outputId": "d98d76bb-2167-4db7-9cbc-7eee30e0d6e5"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[[[ 0.76464176  0.83523     0.8117006 ]\n",
            "   [ 0.7647059   0.8352941   0.8117647 ]\n",
            "   [ 0.77254903  0.84313726  0.81960785]\n",
            "   ...\n",
            "   [ 0.41360295  0.31464463  0.6754289 ]\n",
            "   [ 0.4240809   0.2896446   0.6627451 ]\n",
            "   [ 0.42745095  0.2862745   0.6627451 ]]\n",
            "\n",
            "  [[ 0.7721814   0.8427696   0.8192402 ]\n",
            "   [ 0.77254903  0.84313726  0.81960785]\n",
            "   [ 0.78016526  0.8507535   0.8272241 ]\n",
            "   ...\n",
            "   [ 0.43390298  0.31742013  0.68304515]\n",
            "   [ 0.4240809   0.2896446   0.6627451 ]\n",
            "   [ 0.42745095  0.2862745   0.6627451 ]]\n",
            "\n",
            "  [[ 0.76815164  0.85442615  0.8230536 ]\n",
            "   [ 0.77254903  0.85882354  0.827451  ]\n",
            "   [ 0.78039217  0.8666667   0.8352941 ]\n",
            "   ...\n",
            "   [ 0.45159316  0.31788164  0.690737  ]\n",
            "   [ 0.43192405  0.28180146  0.6627451 ]\n",
            "   [ 0.4352941   0.27843136  0.6627451 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.62352943  0.6313726   0.67058825]\n",
            "   [ 0.6384622   0.6388662   0.6880151 ]\n",
            "   [ 0.69644606  0.6639093   0.7435049 ]\n",
            "   ...\n",
            "   [ 0.5265213   0.50191003  0.69460785]\n",
            "   [ 0.38658088  0.35520834  0.56697303]\n",
            "   [ 0.24155849  0.21018595  0.42195064]]\n",
            "\n",
            "  [[ 0.62352943  0.6313726   0.67058825]\n",
            "   [ 0.64258575  0.6347426   0.68180144]\n",
            "   [ 0.69644606  0.6639093   0.7435049 ]\n",
            "   ...\n",
            "   [ 0.43688726  0.421201    0.6094363 ]\n",
            "   [ 0.35171568  0.32034314  0.53210783]\n",
            "   [ 0.22225124  0.19087869  0.40264344]]\n",
            "\n",
            "  [[ 0.62352943  0.6313726   0.67058825]\n",
            "   [ 0.64258575  0.6347426   0.68180144]\n",
            "   [ 0.69644606  0.6639093   0.7435049 ]\n",
            "   ...\n",
            "   [ 0.39031863  0.37463236  0.56286764]\n",
            "   [ 0.30974263  0.27837008  0.49013478]\n",
            "   [ 0.2069853   0.17561275  0.38737744]]]\n",
            "\n",
            "\n",
            " [[[ 0.38293505 -0.15824139  0.55548406]\n",
            "   [ 0.37337887 -0.16148639  0.5585504 ]\n",
            "   [ 0.31387866 -0.1959573   0.5256274 ]\n",
            "   ...\n",
            "   [ 0.2855538  -0.3811128   0.42673028]\n",
            "   [ 0.302395   -0.36427164  0.44357145]\n",
            "   [ 0.29338235 -0.37328434  0.44240195]]\n",
            "\n",
            "  [[ 0.372549   -0.1686275   0.54509807]\n",
            "   [ 0.36645222 -0.16841304  0.55162376]\n",
            "   [ 0.3165003  -0.19330359  0.528265  ]\n",
            "   ...\n",
            "   [ 0.37372643 -0.29294026  0.51490283]\n",
            "   [ 0.3401121  -0.32655466  0.48128855]\n",
            "   [ 0.3322304  -0.3344363   0.48125   ]]\n",
            "\n",
            "  [[ 0.38367033 -0.17319238  0.5483762 ]\n",
            "   [ 0.37697393 -0.15473557  0.55583423]\n",
            "   [ 0.33330268 -0.17650127  0.5450674 ]\n",
            "   ...\n",
            "   [ 0.41664773 -0.25001895  0.5656674 ]\n",
            "   [ 0.36812407 -0.29854262  0.5171437 ]\n",
            "   [ 0.37371325 -0.29295337  0.52273285]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.5638627  -0.05574524  0.7834705 ]\n",
            "   [ 0.5284182  -0.09703255  0.74413085]\n",
            "   [ 0.47148842 -0.1626414   0.6814149 ]\n",
            "   ...\n",
            "   [ 0.4185121   0.03223759  0.49204606]\n",
            "   [ 0.3377846   0.08932078  0.48014277]\n",
            "   [ 0.3417279   0.19488358  0.5330882 ]]\n",
            "\n",
            "  [[ 0.5670676  -0.0525403   0.7709892 ]\n",
            "   [ 0.510302   -0.13665009  0.6927084 ]\n",
            "   [ 0.486826   -0.19215691  0.64705884]\n",
            "   ...\n",
            "   [ 0.45196962  0.01063544  0.485583  ]\n",
            "   [ 0.48455882  0.06148106  0.5589461 ]\n",
            "   [ 0.44739586  0.12429535  0.6154412 ]]\n",
            "\n",
            "  [[ 0.51940274 -0.10020518  0.7233243 ]\n",
            "   [ 0.48985642 -0.16112399  0.6702486 ]\n",
            "   [ 0.4980392  -0.18431377  0.654902  ]\n",
            "   ...\n",
            "   [ 0.44263244 -0.01211631  0.46616185]\n",
            "   [ 0.48609066  0.03740811  0.55036765]\n",
            "   [ 0.4265012   0.07981002  0.5911765 ]]]], shape=(2, 256, 256, 3), dtype=float32) tf.Tensor([0 6], shape=(2,), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load data from a Generator**"
      ],
      "metadata": {
        "id": "eh7wKIaBbk53"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dummy generator.\n",
        "def generate_features():\n",
        "    # Function to generate a random string.\n",
        "    def random_string(length):\n",
        "        return ''.join(random.choice(string.ascii_letters) for m in range(length))\n",
        "    # Return a random string, a random vector, and a random int.\n",
        "    yield random_string(4), np.random.uniform(size=4), random.randint(0, 10)"
      ],
      "metadata": {
        "id": "sZwHlW2FbfmV"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a numpy array using tf data api with `from_tensor_slices`.\n",
        "data = tf.data.Dataset.from_generator(generate_features, output_types=(tf.string, tf.float32, tf.int32))\n",
        "# Refill data indefinitely.\n",
        "data = data.repeat()\n",
        "# Shuffle data.\n",
        "data = data.shuffle(buffer_size=100)\n",
        "# Batch data.\n",
        "data = data.batch(batch_size=4)\n",
        "# Prefetch data.\n",
        "data = data.prefetch(buffer_size=1)"
      ],
      "metadata": {
        "id": "wr07TtICcL-f"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display data.\n",
        "for batch_str, batch_vector, batch_int in data.take(5):\n",
        "    print(batch_str, batch_vector, batch_int)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F6W3IDaZc1ui",
        "outputId": "f247aa73-29fd-410c-abd8-dbcc8f694678"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([b'kIlI' b'RAzR' b'XNhx' b'Juny'], shape=(4,), dtype=string) tf.Tensor(\n",
            "[[0.836966   0.29700842 0.24015798 0.86873   ]\n",
            " [0.12320157 0.93517476 0.51339155 0.59283787]\n",
            " [0.26115897 0.8187252  0.90030366 0.23011203]\n",
            " [0.45327082 0.9455417  0.16996107 0.5389088 ]], shape=(4, 4), dtype=float32) tf.Tensor([ 5  1  6 10], shape=(4,), dtype=int32)\n",
            "tf.Tensor([b'GNHj' b'gsSM' b'gIJp' b'NJeB'], shape=(4,), dtype=string) tf.Tensor(\n",
            "[[0.1047591  0.99539644 0.29704782 0.606994  ]\n",
            " [0.13766076 0.07080046 0.32486567 0.41179022]\n",
            " [0.68911415 0.9707358  0.41976437 0.351048  ]\n",
            " [0.45072424 0.35818252 0.60431564 0.5289074 ]], shape=(4, 4), dtype=float32) tf.Tensor([7 3 2 2], shape=(4,), dtype=int32)\n",
            "tf.Tensor([b'IMgP' b'iJjU' b'NlyM' b'RjLR'], shape=(4,), dtype=string) tf.Tensor(\n",
            "[[0.23942423 0.0825363  0.6748568  0.16108687]\n",
            " [0.4157596  0.8442947  0.37160802 0.9812635 ]\n",
            " [0.49186072 0.5348949  0.33804983 0.38073397]\n",
            " [0.02785444 0.7672291  0.78736955 0.74145055]], shape=(4, 4), dtype=float32) tf.Tensor([6 7 7 5], shape=(4,), dtype=int32)\n",
            "tf.Tensor([b'bjdh' b'mzeZ' b'ogCp' b'BxzU'], shape=(4,), dtype=string) tf.Tensor(\n",
            "[[0.75336486 0.3967171  0.74790365 0.7295126 ]\n",
            " [0.54904    0.57069063 0.09506162 0.4371179 ]\n",
            " [0.09904131 0.780727   0.94920796 0.97421205]\n",
            " [0.7819954  0.80683255 0.87725097 0.65292525]], shape=(4, 4), dtype=float32) tf.Tensor([ 0  5  4 10], shape=(4,), dtype=int32)\n",
            "tf.Tensor([b'OLtv' b'wRCQ' b'AUzQ' b'kQAs'], shape=(4,), dtype=string) tf.Tensor(\n",
            "[[0.573974   0.8078429  0.3900625  0.8533716 ]\n",
            " [0.2410838  0.05234784 0.9029406  0.6696801 ]\n",
            " [0.6576427  0.05290638 0.67951983 0.109924  ]\n",
            " [0.6488857  0.21849133 0.3970808  0.9077916 ]], shape=(4, 4), dtype=float32) tf.Tensor([3 9 3 0], shape=(4,), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "8rY48EdgWTfM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}